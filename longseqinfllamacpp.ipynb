{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618c50c-cde9-47f3-a469-e6a66c4cb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=\"./lama-gguf/lama-f16.gguf\",\n",
    "      n_gpu_layers=-1, # Uncomment to use GPU acceleration\n",
    "      # seed=1337, # Uncomment to set a specific seed\n",
    "      n_ctx=2048, # Uncomment to increase the context window\n",
    ")\n",
    "excel_file = \"./fb-8b-qa(in).csv\"\n",
    "df = pd.read_csv(excel_file)\n",
    "prompts = df['prompt'].tolist()  # Assuming 'prompt' is the column name in your CSV file\n",
    "responses = []\n",
    "for prompt in tqdm(prompts, desc=\"Generating responses\", unit=\"prompt\"):\n",
    "    output = llm(\n",
    "          f\"Q: {prompt} A: \", # Prompt\n",
    "          max_tokens=520, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "          stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "          echo=False # Echo the prompt back in the output\n",
    "    )\n",
    "    generated_text = output['choices'][0]['text'] \n",
    "    responses.append(generated_text)\n",
    "output_df = pd.DataFrame({'prompt': prompts, 'response': responses})\n",
    "output_file = \"llama-16bit-response.xlsx\"\n",
    "output_df.to_excel(output_file, index=False)\n",
    "print(f\"Responses generated and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0a1b6-657a-4d0a-abee-65a3cd3d23dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
