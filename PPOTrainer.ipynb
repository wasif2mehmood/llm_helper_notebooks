{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36016240-5f3b-45ea-97fe-7c7d26db7fb1",
      "metadata": {
        "id": "36016240-5f3b-45ea-97fe-7c7d26db7fb1",
        "outputId": "911f6e16-fddc-4d39-851e-0bc67ba5daf3"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets peft trl bitsandbytes accelerate wandb sentencepiece ml_dtypes\n",
        "!pip install -q typing-extensions --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb82cd8-8c1c-413a-9d1a-32401feae1e4",
      "metadata": {
        "id": "ccb82cd8-8c1c-413a-9d1a-32401feae1e4",
        "outputId": "26d3be2a-678a-49c7-c483-0a56fb44fa82"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22b38561-b6b7-4ca7-8475-047bb3b7f266",
      "metadata": {
        "id": "22b38561-b6b7-4ca7-8475-047bb3b7f266"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    Adafactor,\n",
        "    AutoTokenizer,\n",
        "    LlamaTokenizer,\n",
        "    HfArgumentParser,\n",
        "    pipeline\n",
        ")\n",
        "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer, set_seed\n",
        "from trl.core import LengthSampler\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44bdd17-703c-4df1-905a-cb029e8ccc87",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6f7ecb2344b446cc94c10b324dd7538f"
          ]
        },
        "id": "e44bdd17-703c-4df1-905a-cb029e8ccc87",
        "outputId": "0f8cca75-7b60-46a4-86ab-91268cadb75a"
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca67ae2-cfe4-4ceb-ac22-0442a08720ab",
      "metadata": {
        "id": "1ca67ae2-cfe4-4ceb-ac22-0442a08720ab"
      },
      "outputs": [],
      "source": [
        "# DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "# DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "# DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "# DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KEN89lfafd2q",
      "metadata": {
        "id": "KEN89lfafd2q"
      },
      "source": [
        "**Models and datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfaa1520-b9c2-4561-9f5d-b0c1cf8f3385",
      "metadata": {
        "id": "bfaa1520-b9c2-4561-9f5d-b0c1cf8f3385"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"berkeley-nest/Nectar\"\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "reward_model_name = \"Nexusflow/Starling-RM-34B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0597c253-094d-4c53-af0a-30dc4bf0ae71",
      "metadata": {
        "id": "0597c253-094d-4c53-af0a-30dc4bf0ae71"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    new_examples = {\n",
        "        \"query\": [],\n",
        "        \"input_ids\": [],\n",
        "    }\n",
        "    for question in examples[\"prompt\"]:\n",
        "        query = \"Question: \" + question + \"\\n\\nAnswer: \"\n",
        "        tokenized_question = tokenizer(query, truncation=True)\n",
        "        new_examples[\"query\"].append(query)\n",
        "        new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"])\n",
        "\n",
        "    return new_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04dbc85b-0a2c-4609-81a9-f089403d7b88",
      "metadata": {
        "id": "04dbc85b-0a2c-4609-81a9-f089403d7b88",
        "outputId": "43e05972-634b-476b-d03e-d91c06f544de"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset(dataset_name, split=\"train\")\n",
        "original_columns = train_dataset.column_names\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aecb3ff9-e7da-40c6-bd8c-406a3d8fc91e",
      "metadata": {
        "id": "aecb3ff9-e7da-40c6-bd8c-406a3d8fc91e",
        "outputId": "d05f817a-aa8b-447a-dc24-480017a72404"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "train_dataset.set_format('pandas')\n",
        "train_dataset = train_dataset[:1101]\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bde9ffa-ca65-4b9b-85df-5fdb9ea36e86",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3d67c7303f0a4907bcc7d60bc83cd1fc",
            "3d3aa84cb85d48cebcb2bed9a945cb65",
            "c331690580b542d2b70e8ce9d5e53c17"
          ]
        },
        "id": "5bde9ffa-ca65-4b9b-85df-5fdb9ea36e86",
        "outputId": "fa09ffc6-94aa-43d4-aedd-11ceb729783d"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if getattr(tokenizer, \"pad_token\", None) is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5582461-b540-4303-8edf-9c3e3ef57e50",
      "metadata": {
        "id": "d5582461-b540-4303-8edf-9c3e3ef57e50",
        "outputId": "560e0500-b08c-4856-de4f-de12b247f40b"
      },
      "outputs": [],
      "source": [
        "tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23b7200-4c8f-4580-890d-fefd6e1b8e5e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d1900035de034a18bc0521e33b34bc8f",
            "7b5f6df18d3047f8953c72e737e99171"
          ]
        },
        "id": "e23b7200-4c8f-4580-890d-fefd6e1b8e5e",
        "outputId": "eea5c4e9-4e71-4cf3-afc5-fd13278384c4"
      },
      "outputs": [],
      "source": [
        "ds = train_dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=original_columns,\n",
        "    )\n",
        "ds = ds.filter(lambda x: len(x[\"input_ids\"]) < 512, batched=False)\n",
        "ds.set_format(type=\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6098301-79ca-40fd-b52b-19d2ca5aa4b8",
      "metadata": {
        "id": "e6098301-79ca-40fd-b52b-19d2ca5aa4b8",
        "outputId": "f55af8e9-7c5d-4e04-c4da-fc7b24b57e07"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9rdioDwfjB6",
      "metadata": {
        "id": "N9rdioDwfjB6"
      },
      "source": [
        "**Lora Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45dbe7f-476b-4193-94ca-f665fd4e85a9",
      "metadata": {
        "id": "f45dbe7f-476b-4193-94ca-f665fd4e85a9"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34bffea7-c09f-47c0-a222-90efdf786019",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0bf5ec1997074bc184fd96a8aec268bb",
            "0b7e9ab807fe42529fcb550d05fe19ad",
            "d37c3729a9294b3daef89cada4cd27b7",
            "33066a174bb044a7b681460d8dafae83",
            "41c488909c2341439d007029215fb1bc",
            "0bdee31658cf45f3afe027dada92e09f",
            "4120707dee394acbb3a19221472eb461",
            "35c0a3dabcd54afcaaf5ee731de7100f",
            "74e3381d59aa42af803112b67137b7ad"
          ]
        },
        "id": "34bffea7-c09f-47c0-a222-90efdf786019",
        "outputId": "93852c1b-c3bf-4ad0-a234-916b5ca0a30a"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map={\"\": 0},\n",
        "    peft_config=lora_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5c9872-f346-4bbb-a447-872a6118ff5d",
      "metadata": {
        "id": "ef5c9872-f346-4bbb-a447-872a6118ff5d"
      },
      "outputs": [],
      "source": [
        "config = PPOConfig(\n",
        "    model_name=model_name,\n",
        "    learning_rate=1.41e-5,\n",
        "    log_with='wandb',\n",
        "    batch_size = 1,\n",
        "    mini_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    ppo_epochs=1\n",
        "    # steps=1080\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b55a2a0-6cf1-4f4e-84e2-bbdfb692e291",
      "metadata": {
        "id": "8b55a2a0-6cf1-4f4e-84e2-bbdfb692e291"
      },
      "outputs": [],
      "source": [
        "# rw_kwargs = {\n",
        "#     \"return_all_scores\": True,\n",
        "#     \"function_to_apply\": \"none\",\n",
        "#     \"batch_size\": 16,\n",
        "#     \"truncation\": True\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf92be2-89f6-4d6c-9bd4-e51193aa6d62",
      "metadata": {
        "id": "ecf92be2-89f6-4d6c-9bd4-e51193aa6d62"
      },
      "outputs": [],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc01078-cb78-4528-9848-ed9e002f7753",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "",
            "d35262e6230942a084db9f36107bfb7a"
          ]
        },
        "id": "acc01078-cb78-4528-9848-ed9e002f7753",
        "outputId": "d12d2480-1009-4be2-807c-488d9575386e"
      },
      "outputs": [],
      "source": [
        "ppo_trainer = PPOTrainer(\n",
        "    config,\n",
        "    model,\n",
        "    ref_model=None,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=ds,\n",
        "    data_collator=collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e1c395-be91-4868-8398-c5e181932757",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "29339606a55140f2acdf36c08f7c7562",
            "ac6d9888defb4a0aafb2c3fb73bfbf0f",
            "ca56e21c8c154f3092cea658288eeb58",
            "984a8ce8d2d34c64a1145359972ac980",
            "706ac2d0a5a44f4ab3638ccb1087702f",
            "cfe24ae43699463cbd9e80d0af21d723",
            "b2d6fde88ee0469bbdbee2ec2c3ec0e9",
            "9ffc53ffd49d4ab6b5d4ec01f5b23533",
            "bcf08ec148d849369fe9c6ce0efceb39",
            "346c403ebb4c47e79027e8099d269e4a",
            "e219ea8f01d148129802e093823fe2e1",
            "1336aa50faa14338a11117e8d6610160",
            "5f5a6c7fe69f40d598f08a882e1607a5",
            "a734120b5d4847ddb76bcc4c91ec11c4",
            "603f51607e67450395dd57daef950267",
            "3195c59d62d646f5a69b89d6ac5f1aca"
          ]
        },
        "id": "45e1c395-be91-4868-8398-c5e181932757",
        "outputId": "3bef4cec-50ed-4094-82e4-3e80b61bbed6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, LlamaPreTrainedModel,LlamaModel\n",
        "import math\n",
        "\n",
        "## Define the reward model function class\n",
        "\n",
        "class LlamaForSequenceClassification(LlamaPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.transformer = LlamaModel(config)\n",
        "        self.v_head = nn.Linear(config.hidden_size, 1, bias=False)\n",
        "        self.PAD_ID = 0\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_device(self):\n",
        "        return self.transformer.device\n",
        "\n",
        "    def forward(\n",
        "          self,\n",
        "          input_ids=None,\n",
        "          past_key_values=None,\n",
        "          attention_mask=None,\n",
        "          position_ids=None,\n",
        "      ):\n",
        "          transformer_outputs = self.transformer(\n",
        "              input_ids,\n",
        "              attention_mask=attention_mask,\n",
        "              position_ids=position_ids,\n",
        "              output_hidden_states=True,\n",
        "          )\n",
        "          hidden_states = transformer_outputs.hidden_states[-1]\n",
        "          scores = []\n",
        "          rewards = self.v_head(hidden_states).squeeze(-1)\n",
        "          bs = int(input_ids.shape[0])\n",
        "          for i in range(bs):\n",
        "              c_inds = (input_ids[i] == self.PAD_ID).nonzero()\n",
        "              c_ind = c_inds[0].item() if len(c_inds) > 0 else input_ids.shape[1]\n",
        "              scores.append(rewards[i, c_ind - 1])\n",
        "          scores = torch.stack(scores)\n",
        "          return {\"scores\": scores}\n",
        "\n",
        "## Load the model and tokenizer\n",
        "\n",
        "reward_model = LlamaForSequenceClassification.from_pretrained(\"Nexusflow/Starling-RM-34B\", load_in_4bit=True)\n",
        "reward_tokenizer = AutoTokenizer.from_pretrained(\"01-ai/Yi-34B-Chat\")\n",
        "reward_tokenizer.truncation_side = \"left\"\n",
        "\n",
        "reward_model.eval().requires_grad_(False)\n",
        "\n",
        "## Define the reward function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb39db7-0bdc-4404-b7b2-6abb8987a962",
      "metadata": {
        "id": "dbb39db7-0bdc-4404-b7b2-6abb8987a962",
        "outputId": "cb184c96-eb74-4158-8c4b-58cb4fb0f402"
      },
      "outputs": [],
      "source": [
        "reward_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5792793c-c171-4648-b6e1-a7486a695915",
      "metadata": {
        "id": "5792793c-c171-4648-b6e1-a7486a695915"
      },
      "outputs": [],
      "source": [
        "reward_device = \"cuda\"\n",
        "reward_batch_size = 1\n",
        "def get_reward(samples):\n",
        "    \"\"\"samples: List[str]\"\"\"\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    encodings_dict = reward_tokenizer(\n",
        "        samples,\n",
        "        truncation=True,\n",
        "        max_length=2048,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(reward_device)\n",
        "    input_ids = encodings_dict[\"input_ids\"]\n",
        "    attention_masks = encodings_dict[\"attention_mask\"]\n",
        "    mbs = reward_batch_size\n",
        "    out = []\n",
        "    for i in range(math.ceil(len(samples) / mbs)):\n",
        "        rewards = reward_model(input_ids=input_ids[i * mbs : (i + 1) * mbs], attention_mask=attention_masks[i * mbs : (i + 1) * mbs])\n",
        "        out.extend(rewards[\"scores\"])\n",
        "    return torch.hstack(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07119bc6-b4ba-4143-8808-d9244efc4f3c",
      "metadata": {
        "id": "07119bc6-b4ba-4143-8808-d9244efc4f3c",
        "outputId": "29eb8950-e93d-4023-92b0-e2e99fab5a19",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "test_sample = [\"<|im_start|>user\\nHello!<|im_end|>\\n<|im_start|>assistant\\nHi, how can I help you?<|im_end|>\"]\n",
        "reward_for_test_sample = get_reward(test_sample)\n",
        "print(reward_for_test_sample)\n",
        "torch.mean(torch.tensor(reward_for_test_sample[0].item())).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b6ffae-50ff-4b77-adac-51312d4c00b0",
      "metadata": {
        "id": "b3b6ffae-50ff-4b77-adac-51312d4c00b0"
      },
      "outputs": [],
      "source": [
        "generation_kwargs = {\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.pad_token_id,\n",
        "    \"eos_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "output_min_length = 32\n",
        "output_max_length = 256\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874a69fd-59e9-4877-b868-82f65938cdf6",
      "metadata": {
        "id": "874a69fd-59e9-4877-b868-82f65938cdf6"
      },
      "outputs": [],
      "source": [
        "# #monitering login\n",
        "# wandb.login(key=\"cb6a8e776ebf15749aef8317fc520c1bc4580ec0\")\n",
        "# run = wandb.init(project='JSL-MedMNX-7B', job_type=\"training\", anonymous=\"allow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4493e944-5e8c-4e55-b8fc-168ff0b8917b",
      "metadata": {
        "id": "4493e944-5e8c-4e55-b8fc-168ff0b8917b"
      },
      "outputs": [],
      "source": [
        "save_freq = 500\n",
        "output_dir = \"./llama-3-ppo\"\n",
        "reward_baseline = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "756ac959-2cf0-4bc1-a0e7-d51464e2a3c0",
      "metadata": {
        "id": "756ac959-2cf0-4bc1-a0e7-d51464e2a3c0"
      },
      "outputs": [],
      "source": [
        "# for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "#     question_tensors = batch[\"input_ids\"]\n",
        "\n",
        "#     response_tensors = ppo_trainer.generate(\n",
        "#         question_tensors,\n",
        "#         return_prompt=False,\n",
        "#         length_sampler=output_length_sampler,\n",
        "#         **generation_kwargs,\n",
        "#     )\n",
        "#     batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
        "\n",
        "#     # Compute sentiment score\n",
        "#     texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "#     reward_outputs = reward_model(texts, **rw_kwargs)\n",
        "#     rewards = [torch.tensor(output[0][\"score\"] - script_args.reward_baseline) for output in reward_outputs]\n",
        "\n",
        "#     # Run PPO step\n",
        "#     stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
        "#     ppo_trainer.log_stats(stats, batch, rewards)\n",
        "\n",
        "#     if script_args.save_freq and epoch and epoch % script_args.save_freq == 0:\n",
        "#         ppo_trainer.save_pretrained(script_args.output_dir + f\"step_{epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094f6498-504c-46a9-a97d-9ff899924ed9",
      "metadata": {
        "id": "094f6498-504c-46a9-a97d-9ff899924ed9",
        "outputId": "ad9778ee-d7da-48aa-f09e-43bd7338c278"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "for epoch in tqdm(range(epochs), \"epoch: \"):\n",
        "    for batch in tqdm(ppo_trainer.dataloader):\n",
        "        question_tensors = batch[\"input_ids\"]\n",
        "\n",
        "        response_tensors = ppo_trainer.generate(\n",
        "            question_tensors,\n",
        "            return_prompt=False,\n",
        "            length_sampler=output_length_sampler,\n",
        "            **generation_kwargs,\n",
        "        )\n",
        "\n",
        "        batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
        "\n",
        "        # Compute sentiment score\n",
        "        texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "        reward_outputs = get_reward(texts)\n",
        "        rewards = [reward_outputs.to(torch.float32) for output in reward_outputs]\n",
        "        # Run PPO step\n",
        "        stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
        "        ppo_trainer.log_stats(stats, batch, rewards)\n",
        "\n",
        "        if save_freq and epoch and epoch % save_freq == 0:\n",
        "            ppo_trainer.save_pretrained(output_dir + f\"step_{epoch}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
