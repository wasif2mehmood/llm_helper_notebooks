{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBC-9Ojahh1x"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/OpenLMLab/collie.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "Mwq_i4e4jXtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from collie.config import CollieConfig\n",
        "from collie.data import CollieDatasetForTraining\n",
        "from collie.data import CollieDataLoader\n",
        "from collie.optim.lomo import Lomo\n",
        "from collie.controller.trainer import Trainer\n",
        "from collie.controller.evaluator import EvaluatorForPerplexity, EvaluatorForGeneration\n",
        "from collie.models.moss_moon import Moss003MoonForCausalLM\n",
        "from collie.utils.monitor import StepTimeMonitor, TGSMonitor, MemoryMonitor, LossMonitor, EvalMonitor\n",
        "from collie.metrics import DecodeMetric, PPLMetric\n",
        "from collie.module import GPTLMLoss\n",
        "from collie.utils.data_provider import GradioProvider"
      ],
      "metadata": {
        "id": "noT1UxknhqwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = CollieConfig.from_pretrained(pretrained_model, trust_remote_code=True)\n",
        "# Note that tp_size * dp_size * pp_size = the number of GPUs\n",
        "# Tensor Parallel\n",
        "config.tp_size = 2\n",
        "# Data Parallel\n",
        "config.dp_size = 1\n",
        "# Pipeline Parallel\n",
        "config.pp_size = 1\n",
        "# the number of training epochs\n",
        "config.train_epochs = 1\n",
        "# eval per {100} steps\n",
        "config.eval_per_n_steps = 100\n",
        "# eval per {1} epoch\n",
        "config.eval_per_n_epochs = 1\n",
        "# The batch_size for each GPU is set to {16}\n",
        "config.train_micro_batch_size = 16\n",
        "# The batch_size for each eval is {1}\n",
        "config.eval_batch_size = 1\n",
        "# DeepSpeed Configuration\n",
        "config.ds_config = {\n",
        "        \"fp16\": {\n",
        "            \"enabled\": True\n",
        "        },\n",
        "        \"zero_allow_untested_optimizer\": True,\n",
        "        \"zero_force_ds_cpu_optimizer\": False,\n",
        "        \"zero_optimization\": {\n",
        "            \"stage\": 3,\n",
        "            \"offload_optimizer\": {\n",
        "                \"device\": \"cpu\",\n",
        "                \"pin_memory\": False\n",
        "            }\n",
        "        },\n",
        "        \"monitor_config\": {\n",
        "            \"enabled\": True,\n",
        "            \"tag\": \"adan\",\n",
        "            \"csv_monitor\": {\n",
        "                \"enabled\": True,\n",
        "                \"output_path\": \"./ds_logs/\"\n",
        "            }\n",
        "        }\n",
        "}"
      ],
      "metadata": {
        "id": "uZgAmqFqhyTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = \"internlm/internlm-7b\""
      ],
      "metadata": {
        "id": "4y3UYT25i1eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "HXx4MsT1h1Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [\n",
        "    {\n",
        "        'input': 'Collie is a python package for ',\n",
        "        'output': 'finetuning large language models.'\n",
        "    } for _ in range(10000)\n",
        "]\n",
        "train_dataset = CollieDatasetForTraining(train_dataset, tokenizer)\n",
        "eval_dataset = train_dataset[:32]"
      ],
      "metadata": {
        "id": "r9ivJJR2ilrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model, config=config)"
      ],
      "metadata": {
        "id": "rVw2GMSSipO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Lomo(\n",
        "    model,\n",
        "    lr = 0.001,\n",
        "    clip_grad_norm = 5.0\n",
        ")"
      ],
      "metadata": {
        "id": "t-acMBIcjA9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monitors = [\n",
        "    # Time used per step\n",
        "    StepTimeMonitor(config),\n",
        "    # Tokens generated per gpu per second\n",
        "    TGSMonitor(config),\n",
        "    # Memory used\n",
        "    MemoryMonitor(config),\n",
        "    # Loss\n",
        "    LossMonitor(config),\n",
        "    # Evaluation Results\n",
        "    EvalMonitor(config)\n",
        "]"
      ],
      "metadata": {
        "id": "xpm7vogxjC0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_ppl = EvaluatorForPerplexity(\n",
        "    model = model,\n",
        "    config = config,\n",
        "    dataset = eval_dataset,\n",
        "    monitors = [\n",
        "        EvalMonitor(config)\n",
        "    ],\n",
        "    metrics = {\n",
        "        'ppl': PPLMetric()\n",
        "    }\n",
        ")\n",
        "evaluator_decode = EvaluatorForGeneration(\n",
        "    model = model,\n",
        "    config = config,\n",
        "    tokenizer = tokenizer,\n",
        "    dataset = eval_dataset,\n",
        "    monitors = [\n",
        "        EvalMonitor(config)\n",
        "    ],\n",
        "    metrics = {\n",
        "        'decode': DecodeMetric()\n",
        "    }\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "9iSMujlPjGPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    config = config,\n",
        "    loss_fn = GPTLMLoss(-100),\n",
        "    optimizer = optimizer,\n",
        "    train_dataset = train_dataset,\n",
        "    monitors = monitors,\n",
        "    evaluators = [evaluator_ppl, evaluator_decode],\n",
        ")\n",
        "# 开始训练/验证\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "O7OEdg88jIbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}